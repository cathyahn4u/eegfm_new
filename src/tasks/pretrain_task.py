# -*- coding: utf-8 -*-
"""
pretrain_task.py
[ê¸°ëŠ¥ ì¶”ê°€] ì‚¬ì „ í•™ìŠµ ì‹œì‘ ì „, configì— ëª…ì‹œëœ 'checkpoint_path'ë¡œë¶€í„°
ì´ì „ í•™ìŠµ ê°€ì¤‘ì¹˜ë¥¼ ë¶ˆëŸ¬ì™€ ì´ì–´ì„œ í•™ìŠµí•˜ëŠ” ë¡œì§ì„ ì¶”ê°€í•©ë‹ˆë‹¤.
"""
import torch
import os
from .base_task import run_one_epoch

def run_pretrain(model, train_loader, val_loader, config, device):
    """ì‚¬ì „ í•™ìŠµ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤."""

    # --- ì²´í¬í¬ì¸íŠ¸ ë¡œë”© ë¡œì§ ---
    if config.checkpoint_path:
        try:
            print(f"ğŸ”„ Resuming pre-training from checkpoint: {config.checkpoint_path}")
            checkpoint = torch.load(config.checkpoint_path, map_location=device)
            
            # ì‚¬ì „ í•™ìŠµì€ ë³´í†µ ë™ì¼í•œ êµ¬ì¡°ì—ì„œ ì´ì–´ê°€ì§€ë§Œ, ìœ ì—°ì„±ì„ ìœ„í•´ strict=False ì‚¬ìš©
            missing_keys, unexpected_keys = model.load_state_dict(checkpoint, strict=False)
            
            print("âœ… Checkpoint loaded successfully.")
            if missing_keys:
                print(f"   - Missing keys: {missing_keys}")
            if unexpected_keys:
                print(f"   - Unexpected keys: {unexpected_keys}")

        except FileNotFoundError:
            print(f"âš ï¸ Checkpoint file not found at {config.checkpoint_path}. Starting pre-training from scratch.")
        except Exception as e:
            print(f"âš ï¸ An error occurred while loading checkpoint: {e}. Starting pre-training from scratch.")
    else:
        print("â„¹ï¸ No checkpoint path provided. Starting pre-training from scratch.")


    optimizer = torch.optim.AdamW(model.parameters(), lr=config.learning_rate, weight_decay=config.weight_decay)
    
    print(f"Starting pre-training for {config.epochs} epochs...")
    best_val_loss = float('inf')
    best_model_state = None

    for epoch in range(config.epochs):
        avg_train_loss = run_one_epoch(model, train_loader, None, optimizer, device, mode='pretrain', is_train=True)
        avg_val_loss = run_one_epoch(model, val_loader, None, None, device, mode='pretrain', is_train=False)
        
        print(f"Epoch {epoch+1}/{config.epochs} | Train Loss = {avg_train_loss:.4f}, Val Loss = {avg_val_loss:.4f}")

        if avg_val_loss < best_val_loss:
            best_val_loss = avg_val_loss
            best_model_state = model.state_dict()
            print(f"ğŸš€ New best validation loss found: {best_val_loss:.4f}")

    print("Pre-training finished.")

    # --- ëª¨ë¸ ì €ì¥ ë¡œì§ ---
    if best_model_state and config.save_path:
        save_dir = os.path.dirname(config.save_path)
        if save_dir and not os.path.exists(save_dir):
            os.makedirs(save_dir)
            
        torch.save(best_model_state, config.save_path)
        print(f"âœ… Best pre-trained model saved to {config.save_path}")

